{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import standard Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Azure ML SDK modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Azure ML SDK version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.57\n"
     ]
    }
   ],
   "source": [
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Azure ML Workspace )or get Workspace Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### following code can be used when there is not such ML workspace existing\n",
    "\n",
    "#AZ_SUBSCRIPTION_ID='7b03fb67-8d44-40ef-9326-c8955518fc75'\n",
    "#ws = Workspace.create(name='rw-ml01-aamls',\n",
    "#                      subscription_id=AZ_SUBSCRIPTION_ID, \n",
    "#                      resource_group='CE-DEV-ROGERLAB-RG',\n",
    "#                      create_resource_group=True,\n",
    "#                      location='westeurope'\n",
    "#                    )\n",
    "#print('\\ncreation completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rw-ml01-aamls\twesteurope\tCE-DEV-ROGERLAB-RG\twesteurope\n"
     ]
    }
   ],
   "source": [
    "#### from azureml.core import Workspace if already existing\n",
    "#### load workspace configuration from the config.json file in the current folder.\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write configuration to local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_config completed\n"
     ]
    }
   ],
   "source": [
    "ws.write_config()\n",
    "print('write_config completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Azure ML Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace=ws, name='salexp-pd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start logging metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.start_logging()                   \n",
    "run.log(\"Experiment start time\", str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load salary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x       y\n",
      "0  0  103100\n",
      "1  1  104900\n",
      "2  2  106800\n",
      "3  3  108700\n",
      "4  4  110400 \n",
      "\n",
      "   x\n",
      "0  0\n",
      "1  1\n",
      "2  2\n",
      "3  3\n",
      "4  4 \n",
      "\n",
      "0    103100\n",
      "1    104900\n",
      "2    106800\n",
      "3    108700\n",
      "4    110400\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sal = pd.read_csv('data/sal.csv',header=0, index_col=None)\n",
    "X = sal[['x']] # change from pd series to array!\n",
    "y = sal['y']\n",
    "\n",
    "print(sal.head(), '\\n')\n",
    "print(X[:5], '\\n')\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  0.9999818159227116\n",
      "testing score:  0.9999698027222448\n"
     ]
    }
   ],
   "source": [
    "lm = LinearRegression() \n",
    "lm.fit(X_train,y_train) \n",
    "\n",
    "print('training score: ', lm.score(X_train,y_train))\n",
    "print('testing score: ', lm.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freeze the model & create a .pkl file being as a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/sal_model.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is the key part - to generate a model from traing classifier!!\n",
    "\n",
    "filename = 'outputs/sal_model.pkl' # give it a name, and best practice is to have an folder named 'outputs/'\n",
    "joblib.dump(lm, filename) # classifer turns to a .pkl file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###alternative way to create the .pkl file\n",
    "###import pickle\n",
    "###pickle.dump(lm, open('outputs/sal_model.pkl','wb'))\n",
    "###loaded_model = pickle.load(open('outputs/sal_model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model by calling the .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158322.15447154472\n"
     ]
    }
   ],
   "source": [
    "filename = 'outputs/sal_model.pkl'\n",
    "loaded_model = joblib.load(filename)\n",
    "\n",
    "# model.predict - use it like a function,\n",
    "y=loaded_model.predict([[30]])[0]   # note: the double [[]], as input will need to be an array! \n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log metrics to Azure ML Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log('Intercept :', lm.intercept_)\n",
    "run.log('Slope :', lm.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End Azure ML Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log(\"Experiment end time\", str(datetime.datetime.now()))\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Portal URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mlworkspace.azure.ai/portal/subscriptions/7b03fb67-8d44-40ef-9326-c8955518fc75/resourceGroups/CE-DEV-ROGERLAB-RG/providers/Microsoft.MachineLearningServices/workspaces/rw-ml01-aamls/experiments/salexp-pd/runs/3b720973-fe7e-4363-abd9-83ba84ca10db\n"
     ]
    }
   ],
   "source": [
    "print(run.get_portal_url())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model sal_model\n"
     ]
    }
   ],
   "source": [
    "model = Model.register(model_path = \"outputs/sal_model.pkl\",\n",
    "                       model_name = \"sal_model\",\n",
    "                       tags = {\"key\": \"1\"},\n",
    "                       description = \"Salary Prediction\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'downloaded_model\\\\sal_model.pkl'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## download the model to hav a look\n",
    "model.download(target_dir='downloaded_model/', exist_ok = True) # folder 'downloaded_model' is being generated here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([139920.39295393, 158322.15447154, 176723.91598916])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = joblib.load('outputs/sal_model.pkl')\n",
    "p.predict([[20],[30],[40]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Azure ML Deploymemt configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.core.webservice.aci.AciServiceDeploymentConfiguration at 0x24ecc8d22b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aciconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create enviroment configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\n",
      "\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "- inference-schema\n",
      "channels:\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Target is to generate an .yml file - package enviornment\n",
    "salenv = CondaDependencies()\n",
    "salenv.add_conda_package(\"scikit-learn\")\n",
    "salenv.add_conda_package(\"inference-schema\")\n",
    "\n",
    "with open(\"salenv.yml\",\"w\") as f:\n",
    "    f.write(salenv.serialize_to_string())\n",
    "with open(\"salenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Azure ML Scoring file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "#from inference_schema.schema_decorators import input_schema, output_schema\n",
    "#from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "#from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # retrieve the path to the model file using the model name\n",
    "    model_path = Model.get_model_path('sal_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "#input_sample = pd.DataFrame(data=[{\n",
    "    # This is a decimal type sample. Use the data type that reflects this column in your data\n",
    "#    \"age\": 28,\n",
    "    # This is a string type sample. Use the data type that reflects this column in your data\n",
    "    #\"input_name_2\": \"value2\",\n",
    "    # This is a integer type sample. Use the data type that reflects this column in your data\n",
    "   # \"input_name_3\": 3\n",
    "#}])\n",
    "\n",
    "# This is a integer type sample. Use the data type that reflects the expected result\n",
    "#output_sample = np.array([0])\n",
    "\n",
    "\n",
    "#@input_schema('data', PandasParameterType(input_sample))\n",
    "#@output_schema(NumpyParameterType(output_sample))\n",
    "\n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # make prediction\n",
    "    y_hat = model.predict(data)\n",
    "    return json.dumps(y_hat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy the model to Azure Container Instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_config completed!\n",
      "Wall time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "### this orginal script does not work\n",
    "\n",
    "#%%time\n",
    "#image_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n",
    "                                                  runtime=\"python\", \n",
    "                                                  conda_file=\"salenv.yml\")\n",
    "#print('image_config completed!')\n",
    "#image_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"Salary\",  \"method\" : \"sklearn\"}, \n",
    "                                               description='Predict Stackoverflow Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n",
      "Running.......................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(runtime= \"python\", \n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"salenv.yml\")\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                       name='sal-predic-svc', \n",
    "                       models=[model], \n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expose web service / Get the web serive info from Workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the service delopyed uri is as following : \n",
      "http://50353d27-0ed3-4a70-81df-24f786986a0b.westeurope.azurecontainer.io/score\n",
      "http://50353d27-0ed3-4a70-81df-24f786986a0b.westeurope.azurecontainer.io/swagger.json\n"
     ]
    }
   ],
   "source": [
    "#services = Webservice.list(ws)\n",
    "#print(services[0].scoring_uri)\n",
    "#print(services[0].swagger_uri)\n",
    "#print('\\n')\n",
    "\n",
    "# FROM SERVICE NAME TO GET THE SERVICE OBJECT\n",
    "service = Webservice(workspace=ws, name='sal-predic-svc')\n",
    "\n",
    "print('the service delopyed uri is as following : ')\n",
    "print(service.scoring_uri)\n",
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Web Service URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://50353d27-0ed3-4a70-81df-24f786986a0b.westeurope.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": \"Expects Content-Type to be application/json\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    73  100    58  100    15    109     28 --:--:-- --:--:-- --:--:--   137\n",
      "100    73  100    58  100    15    109     28 --:--:-- --:--:-- --:--:--   137\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "\t-H 'Content-Type':'application/json' \\\n",
    "\t-d '{\"data\":[[45]]}' \\\n",
    "\thttp://50353d27-0ed3-4a70-81df-24f786986a0b.westeurope.azurecontainer.io/score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consume the service by calling HTTP endpoint (REST API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST to url http://50353d27-0ed3-4a70-81df-24f786986a0b.westeurope.azurecontainer.io/score\n",
      "input data:\n",
      " {\"data\": [[35], [40], [26]]}\n",
      "\n",
      "prediction out is as following:\n",
      " \"[167523.0352303523, 176723.9159891599, 150961.44986449866]\"\n",
      "\n",
      "resp output type as: <class 'requests.models.Response'>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# send a random row from the test set to score\n",
    "\n",
    "data = {\"data\":\n",
    "        [\n",
    "            [35],\n",
    "            [40],\n",
    "            [26]\n",
    "        ]\n",
    "        }\n",
    "\n",
    "# Convert to JSON string\n",
    "input_data = json.dumps(data)\n",
    "\n",
    "#input_data = \"{\\\"data\\\": [\" + str(list(X_test[random_index])) + \"]}\"\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "# for AKS deployment you'd need to the service key in the header as well\n",
    "# api_key = service.get_key()\n",
    "# headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n",
    "\n",
    "scoring_uri = service.scoring_uri\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "\n",
    "\n",
    "print(\"POST to url\", scoring_uri)\n",
    "print(\"input data:\\n\", input_data)\n",
    "\n",
    "print(\"\\nprediction out is as following:\\n\", resp.text)\n",
    "\n",
    "print('\\nresp output type as:', type(resp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete Workspace and clean up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
